{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07b94f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "193d1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class l_svm():\n",
    "    \n",
    "    def __init__(self, lr=0.01, itr=1000):\n",
    "        self.lr = lr\n",
    "        self.itr = itr\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def fit(self, X,y):\n",
    "        samples, feat = X.shape\n",
    "        \n",
    "        self.w = np.zeros(feat)\n",
    "        self.b = 0\n",
    "        \n",
    "        labels = np.ones(samples)\n",
    "        \n",
    "        j = 0\n",
    "        for s in y:\n",
    "            if s <= 0:\n",
    "                labels[j] = -1\n",
    "            j += 1\n",
    "            \n",
    "        for i in range(self.itr):\n",
    "            c = 0\n",
    "            for x_i in X: \n",
    "                # check if y * (wx - b) >=1 and udpate weights accordingly\n",
    "                if (labels[c] * (np.dot(x_i, self.w) - self.b)) >= 1:\n",
    "                    self.w = self.w - self.lr * self.w\n",
    "                else:\n",
    "                    self.w = self.w - self.lr * (self.w - np.dot(x_i, labels[c]))\n",
    "                    self.b = self.b - self.lr * labels[c]\n",
    "                c += 1\n",
    "                \n",
    "        \n",
    "    def predict(self, X):\n",
    "        pred = np.dot(X, self.w) - self.b   \n",
    "        return pred\n",
    "    \n",
    "    def get_acc(self, X, y_actual):\n",
    "       \n",
    "        pred = np.sign(self.predict(X)) \n",
    "        count = 0\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] == y_test[i]:\n",
    "                count += 1\n",
    "        \n",
    "        return count/len(pred)\n",
    "    \n",
    "    \n",
    "    def plot_db(self, X, y):\n",
    "        \n",
    "        plt.scatter(X[:,0], X[:,1], c=y)\n",
    "        ax = plt.gca()\n",
    "        x_b = ax.get_xlim()\n",
    "        y_b = ax.get_ylim()\n",
    "        xx = np.linspace(x_b[0], x_b[1], 50)\n",
    "        yy = np.linspace(y_b[0], y_b[1], 50)\n",
    "        YY, XX = np.meshgrid(yy, xx)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        Z = self.predict(xy).reshape(XX.shape)\n",
    "        ax.contour(XX, YY, Z, levels=[-1, 0, 1],linestyles=['--', '-', '--'])\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98c9170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class log_reg():\n",
    "    def __init__(self, lr=0.01, itr=1000):\n",
    "        self.lr = lr\n",
    "        self.itr = itr\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "        \n",
    "    def sig(self, x):\n",
    "        return 1.0/(1+np.exp(-x))\n",
    "\n",
    "    def calc_gradient(self, X, y, y_hat, m):\n",
    "        grad = (1/m)*np.dot(X.T,(y_hat - y))   \n",
    "        return grad\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m,n = X.shape\n",
    "        self.w = np.zeros(n)\n",
    "    \n",
    "        for i in range(self.itr):\n",
    "            y_hat = self.sig(np.dot(X, self.w))\n",
    "            grad = self.calc_gradient(X, y, y_hat, m)\n",
    "            self.w = self.w - self.lr * grad\n",
    "            \n",
    "        return \n",
    "        \n",
    "      \n",
    "    def predict(self, X):\n",
    "        return self.sig(np.dot(X, self.w))\n",
    "        \n",
    "        labels = []\n",
    "              \n",
    "        for pred in predictions:\n",
    "            if pred >= 0.5:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "            \n",
    "        labels = np.asarray(labels)\n",
    "        return labels\n",
    "        \n",
    "    \n",
    "    def get_acc(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        \n",
    "        labels = []\n",
    "       \n",
    "        for pred in predictions:\n",
    "            if pred >= 0.5:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "            \n",
    "        labels = np.asarray(labels)\n",
    "        \n",
    "        count = 0\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == y[i]:\n",
    "                count += 1\n",
    "        \n",
    "        return count/len(labels)\n",
    "        \n",
    "    def plot_db(self, X, y):\n",
    "        \n",
    "        plt.scatter(X[:,0], X[:,1], c=y)\n",
    "        x_values = [np.min(X[:, 0]), np.max(X[:, 1])]\n",
    "        y_values = - (np.dot(self.w[0], x_values)) / self.w[1]\n",
    "\n",
    "        plt.plot(x_values, y_values, label='Decision Boundary')\n",
    "        \n",
    "        plt.show()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d727663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kernel_svm():\n",
    "    def __init__(self, lr=0.01, itr=1000, kernel='polynomial', p=2, g=0.1, C=1):\n",
    "        self.lr = lr\n",
    "        self.itr = itr\n",
    "        self.kernel = kernel\n",
    "        self.p = p\n",
    "        self.g = g\n",
    "        self.C = C\n",
    "        self.y_t = None\n",
    "        self.X_t = None\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    def calc_kernel(self, X, Y):\n",
    "        if self.kernel == 'polynomial':\n",
    "            new_X = (np.dot(X, Y.T) + self.C)**self.p\n",
    "            return new_X\n",
    "        elif self.kernel == 'rbf':\n",
    "            new_X = np.exp(-self.g * np.linalg.norm(X[:, np.newaxis] - Y[np.newaxis, :], axis=2) ** 2)\n",
    "            return new_X\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        self.X_t = X\n",
    "        samples, feat = X.shape\n",
    "        \n",
    "        self.w = np.random.random(samples)\n",
    "        self.b = 0\n",
    "        \n",
    "        labels = np.ones(samples)\n",
    "        \n",
    "        j = 0\n",
    "        for s in y:\n",
    "            if s <= 0:\n",
    "                labels[j] = -1\n",
    "            j += 1\n",
    "            \n",
    "        self.y_t = labels\n",
    "        \n",
    "        new_X = self.calc_kernel(X, X)\n",
    "\n",
    "        for i in range(self.itr):\n",
    "            grad = np.ones(samples) - np.dot(np.outer(labels,labels)*new_X, self.w)\n",
    "            \n",
    "            self.w = self.w + self.lr * grad\n",
    "            \n",
    "            #constraints\n",
    "            for j in range(len(self.w)):\n",
    "                if(self.w[j] > self.C):\n",
    "                    self.w[j] = self.C\n",
    "                elif(self.w[j] < 0):\n",
    "                    self.w[j] = 0\n",
    "            \n",
    "        \n",
    "        b_s = []\n",
    "        for a in range(len(self.w)):\n",
    "            if (self.w[a] < self.C and self.w[a] > 0):\n",
    "                b_s.append(labels[a] - (self.w *labels).dot(self.calc_kernel(X, X[a])))\n",
    "           \n",
    "        return\n",
    "        \n",
    "     \n",
    "    \n",
    "    def get_acc(self, X, y_actual):\n",
    "        X = self.calc_kernel(self.X_t, X)\n",
    "        \n",
    "        pred = np.dot(self.w * self.y_t, X) - self.b   \n",
    "        pred = np.sign(pred)\n",
    "        \n",
    "        count = 0\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] == y_test[i]:\n",
    "                count += 1\n",
    "        \n",
    "        return count/len(pred)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.calc_kernel(self.X_t, X)\n",
    "        pred = np.dot(self.w * self.y_t, X) - self.b   \n",
    " \n",
    "        return pred\n",
    "    \n",
    "    def plot_db(self, X, y):\n",
    "        plt.scatter(X[:,0], X[:,1], c=y)\n",
    "        ax = plt.gca()\n",
    "        x_b = ax.get_xlim()\n",
    "        y_b = ax.get_ylim()\n",
    "        xx = np.linspace(x_b[0], x_b[1], 50)\n",
    "        yy = np.linspace(y_b[0], y_b[1], 50)\n",
    "        YY, XX = np.meshgrid(yy, xx)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        Z = self.predict(xy).reshape(XX.shape)\n",
    "        ax.contour(XX, YY, Z, levels=[-1, 0, 1],linestyles=['--', '-', '--'])\n",
    "       \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa1b706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kernel_log_reg():\n",
    "    def __init__(self, lr=0.01, itr=1000):\n",
    "        self.lr = lr\n",
    "        self.itr = itr\n",
    "        self.w = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.a = None\n",
    "        \n",
    "     \n",
    "    \n",
    "    def kernel(self, X, y):\n",
    "        k = np.zeros([X.shape[0], y.shape[0]])\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(y.shape[0]):\n",
    "                if ((np.rint(X[i]) == np.rint(y[j])).all()):\n",
    "                    k[i][j] = 1\n",
    "                else:\n",
    "                    k[i][j] = 0\n",
    "                    \n",
    "        return k\n",
    "     \n",
    "    \n",
    "    def sig(self, x):\n",
    "        return 1.0/(1+np.exp(-x))\n",
    "\n",
    "    def calc_gradient(self, X, y):\n",
    "        grad = np.dot(X, y - self.sig(np.dot(X, self.a)))   \n",
    "        return grad\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m,n = X.shape\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.a = np.zeros(m)\n",
    "        K = self.kernel(X,X)\n",
    "        for i in range(self.itr):\n",
    "            grad = self.calc_gradient(K, y)\n",
    "            self.a = self.a + grad * self.lr\n",
    "        return \n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = self.sig(np.dot((self.kernel(self.X, X)).T, self.a))\n",
    "        #print(predictions)\n",
    "        #print(self.a)\n",
    "        labels = []\n",
    "              \n",
    "        for pred in predictions:\n",
    "            if pred >= 0.5:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "            \n",
    "        labels = np.asarray(labels)\n",
    "        return labels\n",
    "    \n",
    "    def get_acc(self, X, y_test):\n",
    "        \n",
    "        pred = self.predict(X)\n",
    "        count = 0\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] == y_test[i]:\n",
    "                count += 1\n",
    "        \n",
    "        return count/len(pred)\n",
    "\n",
    "    def plot_db(self, X, y):\n",
    "        plt.scatter(X[:,0], X[:,1], c=y)\n",
    "        ax = plt.gca()\n",
    "        x_b = ax.get_xlim()\n",
    "        y_b = ax.get_ylim()\n",
    "        xx = np.linspace(x_b[0], x_b[1], 50)\n",
    "        yy = np.linspace(y_b[0], y_b[1], 50)\n",
    "        YY, XX = np.meshgrid(yy, xx)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        Z = self.predict(xy).reshape(XX.shape)\n",
    "        ax.contour(XX, YY, Z, levels=[-1, 0, 1],linestyles=['--', '-', '--'])\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f60d6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def besthyperparms_knn(x, y):\n",
    "  # Finding the best set of hyperparameters for knn using sklearn gridsearch CV\n",
    "  #Consider three hyperparameters# 1. \n",
    "  #n_neighbors: Decide the best k \n",
    "  #weights: adding the weights to data points. 'uniform' ->no weight, \n",
    "  #'distance' weighs points by the inverse of their distances meaning nearer points will have more weight than the farther points.\n",
    "  #metric: The distance metric for similarity.\n",
    "  grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
    "                'weights' : ['uniform','distance'],\n",
    "                'metric' : ['minkowski','euclidean','manhattan']}\n",
    "  gs = GridSearchCV(neighbors.KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "  g_res = gs.fit(x, y)\n",
    "  print (\"Best Score: \",g_res.best_score_)\n",
    "  print (\"Best Hyperparameters: \", g_res.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d2e05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "(569, 30) (569,)\n",
      "Features:30, samples:569\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "data = datasets.load_breast_cancer()\n",
    "print(data.keys())\n",
    "#print(data.DESCR)\n",
    "# Store the feature data\n",
    "X = data.data\n",
    "# store the target data\n",
    "y = data.target\n",
    "samp, feat = X.shape\n",
    "print(X.shape, y.shape)\n",
    "print (\"Features:%d, samples:%d\"%(feat, samp))\n",
    "# split the data using Scikit-Learn's train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab0212a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best Score:  0.931924882629108\n",
      "Best Hyperparameters:  {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "#get the best hyperparameters for knn for this dataset\n",
    "besthyperparms_knn(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a99c9",
   "metadata": {},
   "source": [
    "# Find accuracy for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b5bfaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='manhattan')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bacfa7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(alpha=1, hidden_layer_sizes=(30,), \n",
    "                     random_state=1,max_iter=1000)\n",
    "nn.fit(X_train, y_train)\n",
    "y_pred = nn.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f4ee2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvm = l_svm()\n",
    "lsvm.fit(X_train, y_train)\n",
    "\n",
    "pred = np.sign(lsvm.predict(X_test))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pred)):\n",
    "  if pred[i] <= 0 and y_test[i] == 0:\n",
    "    count += 1\n",
    "  elif pred[i] > 0 and y_test[i] > 0:\n",
    "    count += 1\n",
    "\n",
    "lsvm_acc = count/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e393acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = log_reg()\n",
    "lg.fit(X_train, y_train)\n",
    "lg_acc = lg.get_acc(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54e73bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_lg = kernel_log_reg()\n",
    "k_lg.fit(X_train, y_train)\n",
    "k_lg_acc = k_lg.get_acc(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7d9b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ksvm_rbf = kernel_svm(kernel='rbf', g=1.2, C=10)\n",
    "ksvm_rbf.fit(X_train, y_train)\n",
    "#print(\"Accuracy polynomial SVM\", ksvm_poly.get_acc(X_test, y_test))\n",
    "\n",
    "pred = np.sign(ksvm_rbf.predict(X_test))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pred)):\n",
    "  if pred[i] <= 0 and y_test[i] == 0:\n",
    "    count += 1\n",
    "  elif pred[i] > 0 and y_test[i] > 0:\n",
    "    count += 1\n",
    "\n",
    "rbf_acc = count/len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af48307",
   "metadata": {},
   "source": [
    "ksvm_poly = kernel_svm(kernel='polynomial', p=4, C=2)\n",
    "ksvm_poly.fit(X_train, y_train)\n",
    "#print(\"Accuracy polynomial SVM\", ksvm_poly.get_acc(X_test, y_test))\n",
    "\n",
    "pred = np.sign(ksvm_poly.predict(X_test))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pred)):\n",
    "  if pred[i] <= 0 and y_test[i] == 0:\n",
    "    count += 1\n",
    "  elif pred[i] > 0 and y_test[i] > 0:\n",
    "    count += 1\n",
    "\n",
    "poly_acc = count/len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0bd935",
   "metadata": {},
   "source": [
    "# Results on Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcf67f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN: 0.9440559440559441\n",
      "Accuracy NN: 0.9230769230769231\n",
      "Accuracy Linear SVM:  0.4405594405594406\n",
      "Accuracy Log Reg:  0.48951048951048953\n",
      "Accuracy Kernel Log Reg:  0.5594405594405595\n",
      "Accuracy RBF SVM:  0.9370629370629371\n",
      "Accuracy Polynomial SVM:  0.4405594405594406\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy KNN:\", knn_accuracy)\n",
    "print(\"Accuracy NN:\", nn_accuracy)\n",
    "print(\"Accuracy Linear SVM: \", lsvm_acc)\n",
    "print(\"Accuracy Log Reg: \", lg_acc)\n",
    "print(\"Accuracy Kernel Log Reg: \", k_lg_acc)\n",
    "print(\"Accuracy RBF SVM: \", rbf_acc)\n",
    "print(\"Accuracy Polynomial SVM: \", poly_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d80da5",
   "metadata": {},
   "source": [
    "# L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5af6392a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426, 5)\n",
      "mean perimeter\n",
      "mean area\n",
      "area error\n",
      "worst texture\n",
      "worst area\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "print(X_train.shape)\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False,max_iter=1000).fit(X_train, y_train) \n",
    "model = SelectFromModel(lsvc, prefit=True) \n",
    "X_train_n = model.transform(X_train) \n",
    "print(X_train_n.shape)\n",
    "features = model.get_support()\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "for i in range(30):\n",
    "    if features[i] == True:\n",
    "        print(data.feature_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1024cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f33ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
